import{r as K,j as b}from"./index-WZ944UgW.js";import{T as y,g as _,h as N,f as q,i as T,M as C,r as H,d as W,c as Q,b as X,p as Z,j as ee,k as te,l as J,m as re,a as oe,s as ne,G as se}from"./streetInterviewPrompts-Dzu83YwK.js";import{s as P}from"./settingsService-CbIZ9NBp.js";const we=({imageUrl:t,onClose:n})=>(K.useEffect(()=>{const o=s=>{s.key==="Escape"&&n()};return window.addEventListener("keydown",o),()=>{window.removeEventListener("keydown",o)}},[n]),b.jsxs("div",{className:"fixed inset-0 bg-black bg-opacity-80 flex items-center justify-center z-50 p-4 transition-opacity duration-300",onClick:n,role:"dialog","aria-modal":"true",children:[b.jsx("button",{className:"absolute top-4 right-4 text-white text-4xl font-bold hover:text-gray-300 transition-colors z-50",onClick:n,"aria-label":"Close image viewer",children:"×"}),b.jsx("div",{className:"relative max-w-full max-h-full",onClick:o=>o.stopPropagation(),children:b.jsx("img",{src:t,alt:"Full size view",className:"block max-w-[95vw] max-h-[95vh] object-contain rounded-lg shadow-2xl"})})]})),ae={type:y.OBJECT,properties:{musicAndPacing:{type:y.STRING,description:"An overall description of the video's music, sound effects, and editing pace."},sceneBreakdown:{type:y.ARRAY,description:"A detailed breakdown of each scene in the video.",items:{type:y.OBJECT,properties:{scene_id:{type:y.INTEGER,description:"Sequential ID for the scene, starting from 1."},type:{type:y.STRING,description:"The marketing purpose of the scene. Must be one of: problem, product, benefit, proof, social-proof, mechanism, offer, CTA."},time:{type:y.STRING,description:"The estimated start and end time of the scene in 'MM:SS-MM:SS' format."},visual:{type:y.STRING,description:"A detailed description of the visuals in this scene."},speech:{type:y.STRING,description:"A transcript of the voice-over or any on-screen text in this scene. If none, state 'No speech or text'."}},required:["scene_id","type","time","visual","speech"]}}},required:["musicAndPacing","sceneBreakdown"]},ie='You are a professional video ad deconstructor. Your mission is to analyze a sequence of keyframes from a video ad and output a structured breakdown in JSON format.\n\n**Nhiệm vụ (Your tasks):**\n1.  **Tự động cắt scene theo timestamp (Automatically cut scenes by timestamp):** Based on the sequence of frames provided, identify distinct scenes. A scene is a continuous shot or a series of closely related shots. Estimate the start and end time for each scene. You are given frames captured at a specific FPS from a video of a certain duration. Use this information to calculate the timestamps accurately.\n2.  **Gán nhãn scene (Label the scene):** For each scene, assign a label that best describes its marketing purpose. You MUST use one of the following labels: `problem`, `product`, `benefit`, `proof`, `social-proof`, `mechanism`, `offer`, `CTA`.\n3.  **Trích xuất (Extract):**\n    *   **visual description:** For each scene, provide a detailed description of what is happening visually.\n    *   **kịch bản voice-over:** For each scene, transcribe any audible speech or text that appears on screen. If there is no speech or text, state "No speech or text."\n    *   **âm nhạc/nhịp độ:** Provide a single, overall summary of the video\'s music, sound design, and editing rhythm.\n\n**Đầu ra (Output):**\nYou MUST return a single JSON object that strictly adheres to the provided schema, representing the scene breakdown table (`scene_id`, `type`, `time`, `visual`, `speech`) and the overall `musicAndPacing`.',ce=`You are an expert scriptwriter for high-converting short-form video ads. Your task is to create a NEW script for a NEW product, but you must strictly follow the structure and pacing of an existing successful ad.

**You will be given:**
1.  **Original Ad Analysis:** A detailed scene-by-scene breakdown of the original ad, including scene types and an overall music/pacing description.
2.  **New Product Information:** Key benefits, features, and details about the new product.
3.  **New Target Audience:** The specific audience for the new ad.
4.  **New Big Idea:** The core message for the new product.
5.  **New Product Image:** An image of the new product you are writing the script for.
6.  **New Character/Reviewer Image (Optional):** An image of the person to feature in the new ad.

**YOUR CRITICAL TASK:**
Write a new voiceover script that:
*   Has the **exact same number of scenes** as the original ad's breakdown.
*   Follows the **same sequence of scene types** (e.g., if the original was \`problem\`, \`product\`, \`benefit\`, your new script should also be written for scenes with that purpose in that order).
*   Is written with a rhythm and line length that matches the original's **musicAndPacing** description.
*   Uses language and a tone appropriate for the **New Target Audience**.
*   Accurately incorporates the **New Product Information** into the script.
*   Communicates the **New Big Idea** for the **New Product**.
*   **If a new character image is provided, ensure the script's tone and persona match the person in the image.**
*   The script should be returned as a single JSON object with a "script" key, with each line representing a new scene.
`,pe=`You are an expert video director specializing in recreating the structure and style of successful ads for new brands. Your task is to generate a detailed storyboard for a new script, using a deep analysis of a competitor's ad as a blueprint.

**You will be provided with:**
1.  **Original Ad's Analysis:** A JSON object containing a scene-by-scene breakdown (\`sceneBreakdown\`) of the original ad. Each scene includes its \`type\` (marketing objective), \`time\` (duration), \`visual\` (description of layout and content), and \`speech\`.
2.  **New Product Information:** Key benefits, features, and details about the new product.
3.  **New Target Audience:** The specific audience for the new ad. This should influence the choice of characters, environments, and overall aesthetic.
4.  **New Script:** The finalized voiceover script for the new product. Each line of this script corresponds to a scene in the original ad's breakdown.
5.  **New Product Image:** An image of the new product to be featured.
6.  **New Character/Reviewer Image (Optional):** An image of the person to feature in the new ad.

**YOUR CRITICAL TASK: STORYBOARD RECREATION**
For each line of the **New Script**, you must generate a **voiceover guide**, an **image prompt**, and a **video motion prompt**. You must meticulously recreate the structure of the original scene while adapting the content for the new brand.

**For each scene, you MUST follow this process:**
1.  **Identify the Blueprint:** Look at the corresponding scene in the **Original Ad's Analysis** (e.g., for the first line of the new script, use \`scene_id: 1\` from the analysis).
2.  **Objective (Mục tiêu):** Use the \`type\` (e.g., 'problem', 'benefit') from the original analysis to guide the tone and purpose of your generated prompts.
3.  **Layout & Visual Cue (Bố cục & Visual Cue):** Analyze the \`visual\` description from the original scene. Your new \`imagePrompt\` MUST recreate the same **layout, camera angle, and core visual elements**, but replace the original product/subject with the **New Product** (from the new product image) and the character from the **New Character/Reviewer Image** (if provided). If no character image is provided, invent one that fits the **New Target Audience**. The setting should also resonate with the new audience.
4.  **Duration & Pacing (Thời lượng):** Use the \`time\` (e.g., "00:02-00:05") from the original scene to inform the complexity and action in your prompts. A short duration implies a quick, simple shot. Your \`videoPrompt\` should describe an action that fits within this timeframe.
5.  **Key Message (Thông điệp):** The corresponding line from the **New Script** is your key message. Your prompts must create visuals that directly support and illustrate this new message.

**Example Process for Scene 1:**
- **Original Analysis (Scene 1):** \`type: 'problem'\`, \`time: '00:00-00:03'\`, \`visual: 'A close-up shot of a woman looking tired in a dimly lit office.'\`
- **New Script (Line 1):** "Can't focus on your work?"
- **Your Task:** Generate prompts for a **close-up shot** of a **new character** (who fits the new target audience) who looks **tired** in an **office setting**. The scene should feel like it's about a 'problem' and last about 3 seconds. The visuals must clearly convey "Can't focus on your work?". The new product should not be visible yet, just like the original problem-focused scene.

You will return a JSON object that strictly adheres to the provided schema. The \`voiceoverScript\` in your output MUST be the exact line from the new input script.`,le=`You are an expert director for short-form explainer videos. Your task is to take a full script and a global visual style, and break the script down into a highly granular storyboard where each scene corresponds to only 2-3 seconds of narration.

**CRITICAL INSTRUCTIONS:**

1.  **SEGMENTATION:** You MUST break the provided script into very small, consecutive chunks. Each chunk will be the 'voiceoverScript' for a new scene. A good rule of thumb is 10-15 words per chunk, representing about 2-3 seconds of speech.

2.  **VISUAL STYLE ADHERENCE:** You will be given a [Global Visual Style]. Every single 'imagePrompt' and 'videoPrompt' you generate MUST strictly adhere to this style. For example, if the style is "Claymation", every prompt must describe a scene that looks like it's made of clay.

3.  **ILLUSTRATIVE B-ROLL:** Every scene MUST be an illustrative B-roll shot. This means you should generate a visual metaphor or a literal depiction of what is being discussed in that tiny script chunk. DO NOT show a person talking to the camera.

4.  **PROMPT GENERATION:** For each script chunk, you MUST generate:
    *   **voiceoverScript:** The exact 2-3 second script chunk.
    *   **voiceoverGuide:** A concise guide for delivery (e.g., "clear and informative," "upbeat and engaging").
    *   **imagePrompt:** A detailed prompt for the scene's starting frame, adhering to the [Global Visual Style].
    *   **videoPrompt:** A concise description of simple movement within the scene (e.g., "A line draws itself connecting two points," "The camera slowly pushes in on the main object"), also adhering to the [Global Visual Style].

You will return the response as a single JSON object that strictly adheres to the provided schema, containing a long array of these short scenes.`,g=()=>{const t=P.getGeminiApiKey();if(!t)throw new Error("Gemini API Key not found. Please configure it in the Settings module.");return new se({apiKey:t})},w=t=>({voiceoverScript:t.voiceoverScript||"",voiceoverGuide:t.voiceoverGuide||"",imagePrompt:t.imagePrompt||"",videoPrompt:t.videoPrompt||"",id:crypto.randomUUID(),images:[],isGeneratingImage:!1,imageGenerationError:null,isGeneratingImagePrompt:!1,isGeneratingVideoPrompt:!1,selectedImageForVideo:void 0,videos:[],isGeneratingVideo:!1,videoGenerationError:null,shouldUpscaleVideo:!1,imageFocusObject:"",imageCameraAngle:"",videoCameraMovement:"Static",videoShootingEffect:"",isGeneratingAudio:!1,audioUrl:void 0,audioGenerationError:null,includeDialogueInPrompt:t.includeDialogueInPrompt!==!1}),de=`You are an expert creative director and prompt engineer for an AI image and video generation platform. Your task is to take a simple scene description and expand it into a detailed, professional-grade prompt suitable for a generative AI model.

You will be given the following context:
- **Project-Level Context:** Overall information about the video (e.g., product, theme, visual style, target audience).
- **Scene-Level Context:** The specific voiceover script for this scene and any existing simple prompt ideas.
- **Prompt Type:** Whether you need to generate an 'Image Prompt' (for a static starting frame) or a 'Video Motion Prompt' (for the action within the scene).
- **Character/Product Analysis:** Descriptions based on provided images.

**YOUR CRITICAL TASK:**

**If 'Prompt Type' is 'Image Prompt':**
- Generate a rich, descriptive paragraph.
- Describe the composition, camera angle, lighting, colors, and mood in detail.
- Incorporate the project-level visual style and context.
- Based on the Character/Product Analysis, describe any characters (their appearance, clothing, expression) and how they interact with the product or environment.
- Ensure the visual you describe directly supports the scene's voiceover script.

**If 'Prompt Type' is 'Video Motion Prompt':**
- Generate a concise, action-oriented description of movement.
- Describe camera movement (e.g., "slow dolly in," "pan left") and/or subject movement (e.g., "the character smiles and picks up the bottle").
- The motion should be simple and fit within a short scene (2-4 seconds).
- The action must relate directly to the voiceover script and the starting image prompt.

**RULES:**
- You MUST only return a single string containing the generated prompt.
- DO NOT return JSON or any other formatting. Just the raw text of the prompt itself.`,ve=async(t,n,o,s,e)=>{const i=g();try{const a=[{text:`**Project-Level Context:**
${t}

**Scene-Level Context:**
- Voiceover Script: "${n.voiceoverScript}"
- Existing Image Prompt Idea: "${n.imagePrompt}"
- Existing Video Prompt Idea: "${n.videoPrompt}"

**Your Task:** Generate an enhanced **${o==="image"?"Image Prompt":"Video Motion Prompt"}** for this scene.
`}];return s&&a.push({inlineData:{mimeType:"image/jpeg",data:s.split(",")[1]}}),e&&a.push({inlineData:{mimeType:"image/jpeg",data:e.split(",")[1]}}),(await i.models.generateContent({model:"gemini-2.5-flash",contents:{parts:a},config:{systemInstruction:de,temperature:.7}})).text.trim()}catch(r){throw console.error(`Error generating enhanced ${o} prompt:`,r),new Error(`Failed to generate a suggestion for the ${o} prompt.`)}},Se=async(t,n,o,s,e,i,r,a)=>{const c=g();try{let p=`Video Angle/Core Idea: ${t}
Call to Action: ${s}`;i&&(p+=`
Product Info & Key Benefits: ${i}`),r&&(p+=`
Target Audience: ${r}`);const d=_+`

**Output Language:** You MUST generate the script strictly in **${o}**.`,l=[{text:p}];l.push({inlineData:{mimeType:"image/jpeg",data:e.split(",")[1]}}),a&&l.push({inlineData:{mimeType:"image/jpeg",data:a.split(",")[1]}});const h=(await c.models.generateContent({model:"gemini-2.5-flash",contents:{parts:l},config:{systemInstruction:d,responseMimeType:"application/json",responseSchema:N,temperature:.8,topP:.95}})).text.trim(),u=JSON.parse(h);if(u&&typeof u.script=="string")return u.script;throw new Error("Invalid response format from script generation API.")}catch(p){throw console.error("Error generating voiceover script:",p),new Error("Failed to generate voiceover script. Please check your input or API key and try again.")}},Te=async(t,n,o,s,e,i,r)=>{const a=g();try{const c=`**Finalized Voiceover Script:**
${t}

**Video Angle/Core Idea:** ${n}`;let p=q+`

**Output Language:** You MUST generate all prompts strictly in **${s}**.`;const d=[{text:c}];d.push({inlineData:{mimeType:"image/jpeg",data:e.split(",")[1]}}),r&&d.push({inlineData:{mimeType:"image/jpeg",data:r.split(",")[1]}});const m=(await a.models.generateContent({model:"gemini-2.5-flash",contents:{parts:d},config:{systemInstruction:p,responseMimeType:"application/json",responseSchema:T}})).text.trim(),h=JSON.parse(m);if(h&&Array.isArray(h.scenes))return h.scenes.map(w);throw new Error("Invalid response format from prompts generation API.")}catch(c){throw console.error("Error generating prompts from script:",c),new Error("Failed to generate scene prompts. Please check your script or API key and try again.")}},Ie=async(t,n,o,s)=>{var i,r,a,c,p,d;const e=g();try{let l=t;n&&(l=`(${n}) ${t}`),s&&(l=`[Overall tone: ${s}] ${l}`);const h=(d=(p=(c=(a=(r=(i=(await e.models.generateContent({model:"gemini-2.5-flash-preview-tts",contents:[{parts:[{text:l}]}],config:{responseModalities:[C.AUDIO],speechConfig:{voiceConfig:{prebuiltVoiceConfig:{voiceName:o}}}}})).candidates)==null?void 0:i[0])==null?void 0:r.content)==null?void 0:a.parts)==null?void 0:c[0])==null?void 0:p.inlineData)==null?void 0:d.data;if(!h)throw new Error("Audio data not found in API response.");return h}catch(l){throw console.error("Error generating speech for scene:",l),new Error("Failed to generate speech for scene.")}},be=async(t,n,o,s,e,i)=>{const r=g();try{const c=[{text:`Product Information: ${t}
Core Idea: ${n}
Video Format: ${o}`}];c.push({inlineData:{mimeType:"image/jpeg",data:s.split(",")[1]}}),e&&c.push({inlineData:{mimeType:"image/jpeg",data:e.split(",")[1]}}),i&&c.push({inlineData:{mimeType:"image/jpeg",data:i.split(",")[1]}});const d=(await r.models.generateContent({model:"gemini-2.5-flash",contents:{parts:c},config:{systemInstruction:W,responseMimeType:"application/json",responseSchema:N}})).text.trim(),l=JSON.parse(d);if(l!=null&&l.script)return l.script;throw new Error("Invalid script format received.")}catch(a){throw console.error("Error in generateVoiceoverScriptForSupplements:",a),new Error("Failed to generate voiceover script for supplements.")}},Pe=async(t,n,o,s,e,i,r)=>{const a=g();try{const p=[{text:`Finalized Script:
${t}

Product Info: ${n}
Core Idea: ${o}
Video Format: ${s}`}];p.push({inlineData:{mimeType:"image/jpeg",data:e.split(",")[1]}}),i&&p.push({inlineData:{mimeType:"image/jpeg",data:i.split(",")[1]}}),r&&p.push({inlineData:{mimeType:"image/jpeg",data:r.split(",")[1]}});const l=(await a.models.generateContent({model:"gemini-2.5-flash",contents:{parts:p},config:{systemInstruction:Q,responseMimeType:"application/json",responseSchema:T}})).text.trim(),m=JSON.parse(l);if(m!=null&&m.scenes)return m.scenes.map(w);throw new Error("Invalid storyboard format received.")}catch(c){throw console.error("Error in generatePromptsFromScriptForSupplements:",c),new Error("Failed to generate storyboard prompts for supplements.")}},Ee=async(t,n)=>{const o=g();try{const e=[{text:`Product Information: ${t}`},{inlineData:{mimeType:"image/jpeg",data:n.split(",")[1]}}];return(await o.models.generateContent({model:"gemini-2.5-flash",contents:{parts:e},config:{systemInstruction:H}})).text.trim()}catch(s){throw console.error("Error generating random core idea:",s),new Error("Failed to generate a random core idea.")}},Ae=async(t,n,o)=>{const s=g();try{const i=[{text:`Topic: ${t}
Number of Hosts: ${n}`}];return o.forEach(a=>{i.push({inlineData:{mimeType:"image/jpeg",data:a.split(",")[1]}})}),(await s.models.generateContent({model:"gemini-2.5-flash",contents:{parts:i},config:{systemInstruction:X}})).text.trim()}catch(e){throw console.error("Error generating podcast script:",e),new Error("Failed to generate podcast script.")}},xe=async(t,n,o)=>{const s=g();try{let e=Z;o==="stage"&&(e=e.replace(/podcast studio/g,"stage for a presentation"));const r=[{text:`Podcast Script:
${t}`}];n.forEach(d=>{r.push({inlineData:{mimeType:"image/jpeg",data:d.split(",")[1]}})});const c=(await s.models.generateContent({model:"gemini-2.5-pro",contents:{parts:r},config:{systemInstruction:e,responseMimeType:"application/json",responseSchema:T}})).text.trim(),p=JSON.parse(c);if(p!=null&&p.scenes)return p.scenes.map(w);throw new Error("Invalid storyboard format from podcast analysis.")}catch(e){throw console.error("Error analyzing podcast script:",e),new Error("Failed to analyze podcast script and generate scenes.")}},je=async(t,n,o)=>{const s=g();try{const e=[{text:`Analyze these ${t.length} frames from a ${o.toFixed(1)}-second video, captured at ${n} FPS.`}];t.forEach(a=>{e.push({inlineData:{mimeType:"image/jpeg",data:a.split(",")[1]}})});const r=(await s.models.generateContent({model:"gemini-2.5-pro",contents:{parts:e},config:{systemInstruction:ie,responseMimeType:"application/json",responseSchema:ae}})).text.trim();return JSON.parse(r)}catch(e){throw console.error("Error analyzing video frames:",e),new Error("Failed to analyze video frames.")}},Ne=async(t,n,o,s,e,i)=>{const r=g();try{const c=[{text:`**Original Ad Analysis:**
${JSON.stringify(t,null,2)}

**New Big Idea:** ${n}
**New Product Info:** ${s||"Not provided."}
**New Target Audience:** ${e||"Not provided."}`},{inlineData:{mimeType:"image/jpeg",data:o.split(",")[1]}}];i&&c.push({inlineData:{mimeType:"image/jpeg",data:i.split(",")[1]}});const d=(await r.models.generateContent({model:"gemini-2.5-flash",contents:{parts:c},config:{systemInstruction:ce,responseMimeType:"application/json",responseSchema:N}})).text.trim(),l=JSON.parse(d);if(l!=null&&l.script)return l.script;throw new Error("Invalid script format from cloned script generation.")}catch(a){throw console.error("Error generating cloned script:",a),new Error("Failed to generate cloned script.")}},Ce=async(t,n,o,s,e,i)=>{const r=g();try{const c=[{text:`**Original Ad Analysis:**
${JSON.stringify(t,null,2)}

**New Script:**
${n}

**New Product Info:** ${s||"Not provided."}
**New Target Audience:** ${e||"Not provided."}`},{inlineData:{mimeType:"image/jpeg",data:o.split(",")[1]}}];i&&c.push({inlineData:{mimeType:"image/jpeg",data:i.split(",")[1]}});const d=(await r.models.generateContent({model:"gemini-2.5-pro",contents:{parts:c},config:{systemInstruction:pe,responseMimeType:"application/json",responseSchema:T}})).text.trim(),l=JSON.parse(d);if(l!=null&&l.scenes)return l.scenes.map(w);throw new Error("Invalid storyboard format from cloned storyboard generation.")}catch(a){throw console.error("Error generating cloned storyboard:",a),new Error("Failed to generate cloned storyboard.")}},ke=async(t,n)=>{const o=g(),e=[{text:`Based on the following product information and image, describe the ideal target audience for this product in a short, concise sentence.

Product Info: ${t}`},{inlineData:{mimeType:"image/jpeg",data:n.split(",")[1]}}];return(await o.models.generateContent({model:"gemini-2.5-flash",contents:{parts:e}})).text.trim()},De=async(t,n)=>{const o=g(),e=[{text:`Based on the following product information and image, create a single, powerful "Big Idea" or "Key Message" for an ad campaign. It should be one sentence.

Product Info: ${t}`},{inlineData:{mimeType:"image/jpeg",data:n.split(",")[1]}}];return(await o.models.generateContent({model:"gemini-2.5-flash",contents:{parts:e}})).text.trim()},Oe=async(t,n)=>{const o=g();try{const s=`**Full Script/Topic:**
${t}

**Global Visual Style:** ${n}`,i=(await o.models.generateContent({model:"gemini-2.5-pro",contents:{parts:[{text:s}]},config:{systemInstruction:le,responseMimeType:"application/json",responseSchema:T}})).text.trim(),r=JSON.parse(i);if(r!=null&&r.scenes)return r.scenes.map(w);throw new Error("Invalid storyboard format from explainer storyboard generation.")}catch(s){throw console.error("Error generating explainer storyboard:",s),new Error("Failed to generate explainer storyboard.")}},A=t=>{var e;const[n,o]=t.split(",");if(!n||!o)throw new Error("Invalid Data URL format");const s=(e=n.split(":")[1])==null?void 0:e.split(";")[0];if(!s)throw new Error("Could not determine MIME type from Data URL");return{inlineData:{mimeType:s,data:o}}},$e=async(t,n,o,s,e,i)=>{if(!t)throw new Error("A primary reference image (reporter for two-shot, interviewee for single-shot) must be provided.");const r=g(),a=[];a.push(A(t));let c="one person (the interviewee)";e==="two-shot"&&(c=n?"two people (a reporter and an interviewee)":"one person (the reporter)",n&&a.push(A(n)));const p=`Generate a single, unique, photorealistic background scene for a street interview.

Background description: "${o}".
**CRITICAL INSTRUCTION:** The reporter MUST be holding a microphone.
The scene must have a strict ${i} aspect ratio. It should be composed to feature ${c}. Use the provided image(s) as a reference for the character(s)' appearance. The background should be the main focus, with the characters placed naturally within it. Each generation should produce a slightly different composition or angle.`,d=[...a,{text:p}],l=async()=>{const u=await r.models.generateContent({model:"gemini-2.5-flash-image",contents:{parts:d},config:{responseModalities:[C.IMAGE],imageConfig:{aspectRatio:i}}});for(const f of u.candidates[0].content.parts)if(f.inlineData)return`data:${f.inlineData.mimeType};base64,${f.inlineData.data}`;throw new Error("API did not return any image data in a chunk.")},m=Array(s).fill(null).map(()=>l()),h=await Promise.all(m);if(h.length===0)throw new Error("API did not return any images.");return h},Me=async(t,n,o)=>{const s=g();try{const i=[{text:`Topic: ${t}`},{inlineData:{mimeType:"image/jpeg",data:n.split(",")[1]}},{inlineData:{mimeType:"image/jpeg",data:o.split(",")[1]}}];return(await s.models.generateContent({model:"gemini-2.5-flash",contents:{parts:i},config:{systemInstruction:oe}})).text.trim()}catch(e){throw console.error("Error generating street interview script:",e),new Error("Failed to generate street interview script.")}},Ue=async(t,n,o,s)=>{const e=g();try{const r=[{text:`**Finalized Script:**
${t}`},{inlineData:{mimeType:"image/jpeg",data:n.split(",")[1]}}];o&&r.push({inlineData:{mimeType:"image/jpeg",data:o.split(",")[1]}}),r.push({inlineData:{mimeType:"image/jpeg",data:s.split(",")[1]}});const c=(await e.models.generateContent({model:"gemini-2.5-pro",contents:{parts:r},config:{systemInstruction:ne,responseMimeType:"application/json",responseSchema:J}})).text.trim(),p=JSON.parse(c);if(p!=null&&p.scenes&&p.reporterDescription&&p.intervieweeDescription)return{scenes:p.scenes.map(w),reporterDescription:p.reporterDescription,intervieweeDescription:p.intervieweeDescription};throw new Error("Invalid storyboard format from street interview analysis.")}catch(i){throw console.error("Error analyzing street interview script:",i),new Error("Failed to analyze script and generate scenes.")}},Fe=async(t,n)=>{const o=g();try{const e=[{text:`**Finalized Script:**
${t}`},{inlineData:{mimeType:"image/jpeg",data:n.split(",")[1]}}],r=(await o.models.generateContent({model:"gemini-2.5-pro",contents:{parts:e},config:{systemInstruction:re,responseMimeType:"application/json",responseSchema:J}})).text.trim(),a=JSON.parse(r);if(a!=null&&a.scenes&&a.reporterDescription&&a.intervieweeDescription)return{scenes:a.scenes.map(w),reporterDescription:a.reporterDescription,intervieweeDescription:a.intervieweeDescription};throw new Error("Invalid storyboard format from street interview master shot analysis.")}catch(s){throw console.error("Error analyzing street interview master shot:",s),new Error("Failed to analyze master shot and generate scenes.")}},Re=async(t,n)=>{const o=g();try{const e=[{text:`**Topic:**
${t}`},{inlineData:{mimeType:"image/jpeg",data:n.split(",")[1]}}],r=(await o.models.generateContent({model:"gemini-2.5-pro",contents:{parts:e},config:{systemInstruction:te,responseMimeType:"application/json",responseSchema:ee}})).text.trim(),a=JSON.parse(r);if(a!=null&&a.scenes&&a.reporterDescription&&a.intervieweeDescription&&a.script)return{script:a.script,scenes:a.scenes.map(w),reporterDescription:a.reporterDescription,intervieweeDescription:a.intervieweeDescription};throw new Error("Invalid format from script and storyboard master shot analysis.")}catch(s){throw console.error("Error analyzing master shot and generating script/storyboard:",s),new Error("Failed to analyze master shot and generate script/storyboard.")}},Le=async(t,n,o,s,e)=>{const i=g(),r=t.map(u=>A(u)),a=t.length,c=s==="stage"?"on a modern, well-lit stage for a presentation or talk. It could be a TED-style stage.":"in a modern, professional podcast studio with microphones.",p=`Generate a single, unique camera angle of a scene featuring ${a} ${a>1?"people":"person"} ${c}.

The scene description is: "${n}".

Use the provided reference image(s) for the appearance of the person/people. The final image must have a strict ${e} aspect ratio. The shot should be a varied angle, like a wide shot, medium shot, or over-the-shoulder angle. Each generation should produce a different angle.`,d=[...r,{text:p}],l=async()=>{const u=await i.models.generateContent({model:"gemini-2.5-flash-image",contents:{parts:d},config:{responseModalities:[C.IMAGE],imageConfig:{aspectRatio:e}}});for(const f of u.candidates[0].content.parts)if(f.inlineData)return`data:${f.inlineData.mimeType};base64,${f.inlineData.data}`;throw new Error("API did not return any image data in a chunk.")},m=Array(o).fill(null).map(()=>l()),h=await Promise.all(m);if(h.length===0)throw new Error("API did not return any images.");return h},me="https://api2.lehuyducanh.com/api/video/generate",he="https://api2.lehuyducanh.com/api/image/generate",ue="https://api2.lehuyducanh.com/api/video/upscale",B=t=>{var e;const[n,o]=t.split(",");if(!n||!o)throw new Error("Invalid Data URL format");const s=(e=n.split(":")[1])==null?void 0:e.split(";")[0];if(!s)throw new Error("Could not determine MIME type from Data URL");return{base64:o,mimeType:s}},z=async(t,n,o=1e4,s=2e4,e=3e5)=>{var r,a;const i=Date.now();for(await new Promise(c=>setTimeout(c,s));Date.now()-i<e;){try{const c=await fetch(t,{headers:{"x-api-key":n}});if(!c.ok){console.warn(`Polling failed with status ${c.status}. Retrying...`),await new Promise(d=>setTimeout(d,o));continue}const p=await c.json();if(p.status==="COMPLETE"){if(((r=p.payload)==null?void 0:r.ready)===!0)return p.payload}else if(p.status==="FAILED")throw new Error(`Video job failed on backend: ${((a=p.error)==null?void 0:a.message)||"Unknown reason"}`)}catch(c){if(c instanceof Error&&c.message.startsWith("Video job failed"))throw c;console.error("Transient error during polling, will retry:",c)}await new Promise(c=>setTimeout(c,o))}throw new Error("Video processing timed out after "+e/1e3+" seconds.")},x=async(t,n=5e3,o=18e4)=>{const s=Date.now();for(;Date.now()-s<o;){try{if((await fetch(t,{method:"HEAD"})).ok)return t}catch(e){console.warn("Retrying public URL check after transient error:",e)}await new Promise(e=>setTimeout(e,n))}},j=async(t,n,o=5e3,s=3e5)=>{const e=Date.now();for(;Date.now()-e<s;){try{const i=await fetch(t,{headers:{"x-api-key":n}});if(i.status===200)return await i.blob();if(![202,404,403].includes(i.status)){const r=await i.text();throw new Error(`Failed to download video (status ${i.status}): ${r}`)}}catch(i){console.error("Error during download attempt, retrying...",i)}await new Promise(i=>setTimeout(i,o))}throw new Error("Video download timed out after "+s/1e3+" seconds.")},Ge=async({prompt:t,aspectRatio:n,subjectUrls:o=[],styleUrl:s,sceneUrl:e,referenceUrls:i=[]})=>{var m;const r=P.getBrianApiKey();if(!r)throw new Error("Brian Image/Video API Key not found. Please configure it in the Settings module.");const c={IMAGE_ASPECT_RATIO_LANDSCAPE:"16:9",IMAGE_ASPECT_RATIO_SQUARE:"1:1",IMAGE_ASPECT_RATIO_PORTRAIT:"9:16"}[n];if(!c)throw new Error(`Unsupported aspect ratio for LeHuyDucAnh API: ${n}`);const p=(h,u)=>{const{base64:f,mimeType:v}=B(h);return{base64:f,caption:u,mimeType:v}},d=[...o,...i],l={prompt:t,cleanup:!0,aspectRatio:c};d.length>0&&(l.subjects=d.map((h,u)=>p(h,`subject reference ${u+1}`))),e&&(l.scenes=[p(e,"scene environment")]),s&&(l.styles=[p(s,"global style reference")]);try{const h=await fetch(he,{method:"POST",headers:{"Content-Type":"application/json","x-api-key":r},body:JSON.stringify(l)}),u=await h.json();if(!h.ok){const v=((m=u==null?void 0:u.error)==null?void 0:m.message)||(u==null?void 0:u.message)||JSON.stringify(u);throw new Error(`API request failed with status ${h.status}: ${v}`)}const f=u.urls||(Array.isArray(u)?u:[]);if(!Array.isArray(f)||f.length===0)throw console.error("Invalid or empty response from new image generation API:",u),new Error("Server processed the request successfully, but returned no valid images.");return f}catch(h){throw console.error("Error generating image with LeHuyDucAnh API v2:",h),h instanceof TypeError&&h.message.includes("Failed to fetch")?new Error("Failed to fetch from LeHuyDucAnh API. This is likely a CORS issue, network problem, or invalid API endpoint."):h}},Ve=async({prompt:t,startImageUrl:n,aspectRatio:o,upscale:s})=>{var i;const e=P.getBrianApiKey();if(!e)throw new Error("Brian Image/Video API Key not found. Please configure it in the Settings module.");try{const{base64:r,mimeType:a}=B(n),p=await fetch(me,{method:"POST",headers:{"Content-Type":"application/json","x-api-key":e},body:JSON.stringify({prompt:t,generationMode:"START_ONLY",aspectRatio:o,startImage:{base64:r,mimeType:a},cleanup:!0,upscale:s})}),d=await p.json();if(!p.ok){const m=((i=d==null?void 0:d.error)==null?void 0:i.message)||(d==null?void 0:d.message)||JSON.stringify(d);throw new Error(`API Error (${p.status}): ${m}`)}const l=async m=>{var O,$,M,U,F,R,L,G,V,Y;if(!m.ready||!((O=m.video)!=null&&O.url)&&!(($=m.video)!=null&&$.downloadUrl))throw new Error("Job completed but final video URL was not found.");const h=m.video.url||m.video.downloadUrl,u=m.video.downloadUrl||m.video.url;let f=h?await x(h):void 0,v;if(f)v=f;else{const S=await j(u,e);v=URL.createObjectURL(S)}let E,I;const k=((U=(M=m.upscale)==null?void 0:M.video)==null?void 0:U.url)||((R=(F=m.upscale)==null?void 0:F.video)==null?void 0:R.downloadUrl),D=((G=(L=m.upscale)==null?void 0:L.video)==null?void 0:G.downloadUrl)||((Y=(V=m.upscale)==null?void 0:V.video)==null?void 0:Y.url);if(k&&(I=await x(k)),!I&&D)try{const S=await j(D,e);E=URL.createObjectURL(S)}catch(S){console.error("Could not fetch upscaled video, it might still be processing or failed.",S)}else E=I;return{videoUrl:v,upscaledUrl:E,mediaGenerationId:m.mediaGenerationId,seed:m.seed||0,publicUrl:f,upscaledPublicUrl:I}};if(d.status==="COMPLETE")return await l(d.payload);if(d.status==="PROCESSING"&&d.statusUrl){const m=await z(d.statusUrl,e,d.pollIntervalMs,6e4);return await l(m)}else throw new Error(`Unexpected initial job status: ${d.status||"Unknown"}`)}catch(r){console.error("Error generating video with LeHuyDucAnh API V2:",r);const a=r instanceof Error?r.message:"An unknown error occurred.";throw new Error(`Failed to generate video: ${a}.`)}},Ye=async(t,n)=>{var s;const o=P.getBrianApiKey();if(!o)throw new Error("Brian Image/Video API Key not found. Please configure it in the Settings module.");try{const i=await fetch(ue,{method:"POST",headers:{"Content-Type":"application/json","x-api-key":o},body:JSON.stringify({mediaGenerationId:t,seed:n})}),r=await i.json();if(!i.ok){const c=((s=r==null?void 0:r.error)==null?void 0:s.message)||(r==null?void 0:r.message)||JSON.stringify(r);throw new Error(`API Error (${i.status}): ${c}`)}const a=async c=>{var h,u;if(!((h=c.video)!=null&&h.url)&&!((u=c.video)!=null&&u.downloadUrl))throw new Error("Upscale job completed, but the API did not return a video URL.");const p=c.video.url||c.video.downloadUrl,d=c.video.downloadUrl||c.video.url,l=p?await x(p):void 0;if(l)return{videoUrl:l,publicUrl:l};const m=await j(d,o);return{videoUrl:URL.createObjectURL(m),publicUrl:void 0}};if(r.status==="COMPLETE")return await a(r.payload);if(r.status==="PROCESSING"&&r.statusUrl){const c=await z(r.statusUrl,o,r.pollIntervalMs,2e4);return await a(c)}else throw new Error(`Unexpected initial upscale job status: ${r.status||"Unknown"}`)}catch(e){console.error("Error upscaling video with LeHuyDucAnh API V2:",e);const i=e instanceof Error?e.message:"An unknown error occurred.";throw new Error(`Failed to upscale video: ${i}.`)}};export{we as I,Se as a,Te as b,Ie as c,Ee as d,be as e,Pe as f,ve as g,Ae as h,xe as i,Le as j,g as k,Ge as l,w as m,ke as n,De as o,Ne as p,Ce as q,je as r,Oe as s,$e as t,Re as u,Fe as v,Me as w,Ue as x,Ye as y,Ve as z};
