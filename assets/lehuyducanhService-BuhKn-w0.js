import{r as U,j as T}from"./index-CRGght61.js";import{T as y,g as L,h as A,f as G,i as S,M as x,r as V,d as Y,c as J,b as B,p as z,j as K,k as _,l as M,m as q,a as W,s as H,G as Q}from"./streetInterviewPrompts-Dzu83YwK.js";import{s as I}from"./settingsService-CbIZ9NBp.js";const le=({imageUrl:r,onClose:n})=>(U.useEffect(()=>{const o=s=>{s.key==="Escape"&&n()};return window.addEventListener("keydown",o),()=>{window.removeEventListener("keydown",o)}},[n]),T.jsxs("div",{className:"fixed inset-0 bg-black bg-opacity-80 flex items-center justify-center z-50 p-4 transition-opacity duration-300",onClick:n,role:"dialog","aria-modal":"true",children:[T.jsx("button",{className:"absolute top-4 right-4 text-white text-4xl font-bold hover:text-gray-300 transition-colors z-50",onClick:n,"aria-label":"Close image viewer",children:"×"}),T.jsx("div",{className:"relative max-w-full max-h-full",onClick:o=>o.stopPropagation(),children:T.jsx("img",{src:r,alt:"Full size view",className:"block max-w-[95vw] max-h-[95vh] object-contain rounded-lg shadow-2xl"})})]})),X={type:y.OBJECT,properties:{musicAndPacing:{type:y.STRING,description:"An overall description of the video's music, sound effects, and editing pace."},sceneBreakdown:{type:y.ARRAY,description:"A detailed breakdown of each scene in the video.",items:{type:y.OBJECT,properties:{scene_id:{type:y.INTEGER,description:"Sequential ID for the scene, starting from 1."},type:{type:y.STRING,description:"The marketing purpose of the scene. Must be one of: problem, product, benefit, proof, social-proof, mechanism, offer, CTA."},time:{type:y.STRING,description:"The estimated start and end time of the scene in 'MM:SS-MM:SS' format."},visual:{type:y.STRING,description:"A detailed description of the visuals in this scene."},speech:{type:y.STRING,description:"A transcript of the voice-over or any on-screen text in this scene. If none, state 'No speech or text'."}},required:["scene_id","type","time","visual","speech"]}}},required:["musicAndPacing","sceneBreakdown"]},Z='You are a professional video ad deconstructor. Your mission is to analyze a sequence of keyframes from a video ad and output a structured breakdown in JSON format.\n\n**Nhiệm vụ (Your tasks):**\n1.  **Tự động cắt scene theo timestamp (Automatically cut scenes by timestamp):** Based on the sequence of frames provided, identify distinct scenes. A scene is a continuous shot or a series of closely related shots. Estimate the start and end time for each scene. You are given frames captured at a specific FPS from a video of a certain duration. Use this information to calculate the timestamps accurately.\n2.  **Gán nhãn scene (Label the scene):** For each scene, assign a label that best describes its marketing purpose. You MUST use one of the following labels: `problem`, `product`, `benefit`, `proof`, `social-proof`, `mechanism`, `offer`, `CTA`.\n3.  **Trích xuất (Extract):**\n    *   **visual description:** For each scene, provide a detailed description of what is happening visually.\n    *   **kịch bản voice-over:** For each scene, transcribe any audible speech or text that appears on screen. If there is no speech or text, state "No speech or text."\n    *   **âm nhạc/nhịp độ:** Provide a single, overall summary of the video\'s music, sound design, and editing rhythm.\n\n**Đầu ra (Output):**\nYou MUST return a single JSON object that strictly adheres to the provided schema, representing the scene breakdown table (`scene_id`, `type`, `time`, `visual`, `speech`) and the overall `musicAndPacing`.',ee=`You are an expert scriptwriter for high-converting short-form video ads. Your task is to create a NEW script for a NEW product, but you must strictly follow the structure and pacing of an existing successful ad.

**You will be given:**
1.  **Original Ad Analysis:** A detailed scene-by-scene breakdown of the original ad, including scene types and an overall music/pacing description.
2.  **New Product Information:** Key benefits, features, and details about the new product.
3.  **New Target Audience:** The specific audience for the new ad.
4.  **New Big Idea:** The core message for the new product.
5.  **New Product Image:** An image of the new product you are writing the script for.
6.  **New Character/Reviewer Image (Optional):** An image of the person to feature in the new ad.

**YOUR CRITICAL TASK:**
Write a new voiceover script that:
*   Has the **exact same number of scenes** as the original ad's breakdown.
*   Follows the **same sequence of scene types** (e.g., if the original was \`problem\`, \`product\`, \`benefit\`, your new script should also be written for scenes with that purpose in that order).
*   Is written with a rhythm and line length that matches the original's **musicAndPacing** description.
*   Uses language and a tone appropriate for the **New Target Audience**.
*   Accurately incorporates the **New Product Information** into the script.
*   Communicates the **New Big Idea** for the **New Product**.
*   **If a new character image is provided, ensure the script's tone and persona match the person in the image.**
*   The script should be returned as a single JSON object with a "script" key, with each line representing a new scene.
`,te=`You are an expert video director specializing in recreating the structure and style of successful ads for new brands. Your task is to generate a detailed storyboard for a new script, using a deep analysis of a competitor's ad as a blueprint.

**You will be provided with:**
1.  **Original Ad's Analysis:** A JSON object containing a scene-by-scene breakdown (\`sceneBreakdown\`) of the original ad. Each scene includes its \`type\` (marketing objective), \`time\` (duration), \`visual\` (description of layout and content), and \`speech\`.
2.  **New Product Information:** Key benefits, features, and details about the new product.
3.  **New Target Audience:** The specific audience for the new ad. This should influence the choice of characters, environments, and overall aesthetic.
4.  **New Script:** The finalized voiceover script for the new product. Each line of this script corresponds to a scene in the original ad's breakdown.
5.  **New Product Image:** An image of the new product to be featured.
6.  **New Character/Reviewer Image (Optional):** An image of the person to feature in the new ad.

**YOUR CRITICAL TASK: STORYBOARD RECREATION**
For each line of the **New Script**, you must generate a **voiceover guide**, an **image prompt**, and a **video motion prompt**. You must meticulously recreate the structure of the original scene while adapting the content for the new brand.

**For each scene, you MUST follow this process:**
1.  **Identify the Blueprint:** Look at the corresponding scene in the **Original Ad's Analysis** (e.g., for the first line of the new script, use \`scene_id: 1\` from the analysis).
2.  **Objective (Mục tiêu):** Use the \`type\` (e.g., 'problem', 'benefit') from the original analysis to guide the tone and purpose of your generated prompts.
3.  **Layout & Visual Cue (Bố cục & Visual Cue):** Analyze the \`visual\` description from the original scene. Your new \`imagePrompt\` MUST recreate the same **layout, camera angle, and core visual elements**, but replace the original product/subject with the **New Product** (from the new product image) and the character from the **New Character/Reviewer Image** (if provided). If no character image is provided, invent one that fits the **New Target Audience**. The setting should also resonate with the new audience.
4.  **Duration & Pacing (Thời lượng):** Use the \`time\` (e.g., "00:02-00:05") from the original scene to inform the complexity and action in your prompts. A short duration implies a quick, simple shot. Your \`videoPrompt\` should describe an action that fits within this timeframe.
5.  **Key Message (Thông điệp):** The corresponding line from the **New Script** is your key message. Your prompts must create visuals that directly support and illustrate this new message.

**Example Process for Scene 1:**
- **Original Analysis (Scene 1):** \`type: 'problem'\`, \`time: '00:00-00:03'\`, \`visual: 'A close-up shot of a woman looking tired in a dimly lit office.'\`
- **New Script (Line 1):** "Can't focus on your work?"
- **Your Task:** Generate prompts for a **close-up shot** of a **new character** (who fits the new target audience) who looks **tired** in an **office setting**. The scene should feel like it's about a 'problem' and last about 3 seconds. The visuals must clearly convey "Can't focus on your work?". The new product should not be visible yet, just like the original problem-focused scene.

You will return a JSON object that strictly adheres to the provided schema. The \`voiceoverScript\` in your output MUST be the exact line from the new input script.`,re=`You are an expert director for short-form explainer videos. Your task is to take a full script and a global visual style, and break the script down into a highly granular storyboard where each scene corresponds to only 2-3 seconds of narration.

**CRITICAL INSTRUCTIONS:**

1.  **SEGMENTATION:** You MUST break the provided script into very small, consecutive chunks. Each chunk will be the 'voiceoverScript' for a new scene. A good rule of thumb is 10-15 words per chunk, representing about 2-3 seconds of speech.

2.  **VISUAL STYLE ADHERENCE:** You will be given a [Global Visual Style]. Every single 'imagePrompt' and 'videoPrompt' you generate MUST strictly adhere to this style. For example, if the style is "Claymation", every prompt must describe a scene that looks like it's made of clay.

3.  **ILLUSTRATIVE B-ROLL:** Every scene MUST be an illustrative B-roll shot. This means you should generate a visual metaphor or a literal depiction of what is being discussed in that tiny script chunk. DO NOT show a person talking to the camera.

4.  **PROMPT GENERATION:** For each script chunk, you MUST generate:
    *   **voiceoverScript:** The exact 2-3 second script chunk.
    *   **voiceoverGuide:** A concise guide for delivery (e.g., "clear and informative," "upbeat and engaging").
    *   **imagePrompt:** A detailed prompt for the scene's starting frame, adhering to the [Global Visual Style].
    *   **videoPrompt:** A concise description of simple movement within the scene (e.g., "A line draws itself connecting two points," "The camera slowly pushes in on the main object"), also adhering to the [Global Visual Style].

You will return the response as a single JSON object that strictly adheres to the provided schema, containing a long array of these short scenes.`,g=()=>{const r=I.getGeminiApiKey();if(!r)throw new Error("Gemini API Key not found. Please configure it in the Settings module.");return new Q({apiKey:r})},w=r=>({voiceoverScript:r.voiceoverScript||"",voiceoverGuide:r.voiceoverGuide||"",imagePrompt:r.imagePrompt||"",videoPrompt:r.videoPrompt||"",id:crypto.randomUUID(),images:[],isGeneratingImage:!1,imageGenerationError:null,isGeneratingImagePrompt:!1,isGeneratingVideoPrompt:!1,selectedImageForVideo:void 0,videos:[],isGeneratingVideo:!1,videoGenerationError:null,shouldUpscaleVideo:!1,imageFocusObject:"",imageCameraAngle:"",videoCameraMovement:"Static",videoShootingEffect:"",isGeneratingAudio:!1,audioUrl:void 0,audioGenerationError:null,includeDialogueInPrompt:r.includeDialogueInPrompt!==!1}),oe=`You are an expert creative director and prompt engineer for an AI image and video generation platform. Your task is to take a simple scene description and expand it into a detailed, professional-grade prompt suitable for a generative AI model.

You will be given the following context:
- **Project-Level Context:** Overall information about the video (e.g., product, theme, visual style, target audience).
- **Scene-Level Context:** The specific voiceover script for this scene and any existing simple prompt ideas.
- **Prompt Type:** Whether you need to generate an 'Image Prompt' (for a static starting frame) or a 'Video Motion Prompt' (for the action within the scene).
- **Character/Product Analysis:** Descriptions based on provided images.

**YOUR CRITICAL TASK:**

**If 'Prompt Type' is 'Image Prompt':**
- Generate a rich, descriptive paragraph.
- Describe the composition, camera angle, lighting, colors, and mood in detail.
- Incorporate the project-level visual style and context.
- Based on the Character/Product Analysis, describe any characters (their appearance, clothing, expression) and how they interact with the product or environment.
- Ensure the visual you describe directly supports the scene's voiceover script.

**If 'Prompt Type' is 'Video Motion Prompt':**
- Generate a concise, action-oriented description of movement.
- Describe camera movement (e.g., "slow dolly in," "pan left") and/or subject movement (e.g., "the character smiles and picks up the bottle").
- The motion should be simple and fit within a short scene (2-4 seconds).
- The action must relate directly to the voiceover script and the starting image prompt.

**RULES:**
- You MUST only return a single string containing the generated prompt.
- DO NOT return JSON or any other formatting. Just the raw text of the prompt itself.`,de=async(r,n,o,s,e)=>{const i=g();try{const a=[{text:`**Project-Level Context:**
${r}

**Scene-Level Context:**
- Voiceover Script: "${n.voiceoverScript}"
- Existing Image Prompt Idea: "${n.imagePrompt}"
- Existing Video Prompt Idea: "${n.videoPrompt}"

**Your Task:** Generate an enhanced **${o==="image"?"Image Prompt":"Video Motion Prompt"}** for this scene.
`}];return s&&a.push({inlineData:{mimeType:"image/jpeg",data:s.split(",")[1]}}),e&&a.push({inlineData:{mimeType:"image/jpeg",data:e.split(",")[1]}}),(await i.models.generateContent({model:"gemini-2.5-flash",contents:{parts:a},config:{systemInstruction:oe,temperature:.7}})).text.trim()}catch(t){throw console.error(`Error generating enhanced ${o} prompt:`,t),new Error(`Failed to generate a suggestion for the ${o} prompt.`)}},me=async(r,n,o,s,e,i,t,a)=>{const c=g();try{let p=`Video Angle/Core Idea: ${r}
Call to Action: ${s}`;i&&(p+=`
Product Info & Key Benefits: ${i}`),t&&(p+=`
Target Audience: ${t}`);const l=L+`

**Output Language:** You MUST generate the script strictly in **${o}**.`,d=[{text:p}];d.push({inlineData:{mimeType:"image/jpeg",data:e.split(",")[1]}}),a&&d.push({inlineData:{mimeType:"image/jpeg",data:a.split(",")[1]}});const h=(await c.models.generateContent({model:"gemini-2.5-flash",contents:{parts:d},config:{systemInstruction:l,responseMimeType:"application/json",responseSchema:A,temperature:.8,topP:.95}})).text.trim(),u=JSON.parse(h);if(u&&typeof u.script=="string")return u.script;throw new Error("Invalid response format from script generation API.")}catch(p){throw console.error("Error generating voiceover script:",p),new Error("Failed to generate voiceover script. Please check your input or API key and try again.")}},he=async(r,n,o,s,e,i,t)=>{const a=g();try{const c=`**Finalized Voiceover Script:**
${r}

**Video Angle/Core Idea:** ${n}`;let p=G+`

**Output Language:** You MUST generate all prompts strictly in **${s}**.`;const l=[{text:c}];l.push({inlineData:{mimeType:"image/jpeg",data:e.split(",")[1]}}),t&&l.push({inlineData:{mimeType:"image/jpeg",data:t.split(",")[1]}});const m=(await a.models.generateContent({model:"gemini-2.5-flash",contents:{parts:l},config:{systemInstruction:p,responseMimeType:"application/json",responseSchema:S}})).text.trim(),h=JSON.parse(m);if(h&&Array.isArray(h.scenes))return h.scenes.map(w);throw new Error("Invalid response format from prompts generation API.")}catch(c){throw console.error("Error generating prompts from script:",c),new Error("Failed to generate scene prompts. Please check your script or API key and try again.")}},ue=async(r,n,o,s)=>{var i,t,a,c,p,l;const e=g();try{let d=r;n&&(d=`(${n}) ${r}`),s&&(d=`[Overall tone: ${s}] ${d}`);const h=(l=(p=(c=(a=(t=(i=(await e.models.generateContent({model:"gemini-2.5-flash-preview-tts",contents:[{parts:[{text:d}]}],config:{responseModalities:[x.AUDIO],speechConfig:{voiceConfig:{prebuiltVoiceConfig:{voiceName:o}}}}})).candidates)==null?void 0:i[0])==null?void 0:t.content)==null?void 0:a.parts)==null?void 0:c[0])==null?void 0:p.inlineData)==null?void 0:l.data;if(!h)throw new Error("Audio data not found in API response.");return h}catch(d){throw console.error("Error generating speech for scene:",d),new Error("Failed to generate speech for scene.")}},ge=async(r,n,o,s,e,i)=>{const t=g();try{const c=[{text:`Product Information: ${r}
Core Idea: ${n}
Video Format: ${o}`}];c.push({inlineData:{mimeType:"image/jpeg",data:s.split(",")[1]}}),e&&c.push({inlineData:{mimeType:"image/jpeg",data:e.split(",")[1]}}),i&&c.push({inlineData:{mimeType:"image/jpeg",data:i.split(",")[1]}});const l=(await t.models.generateContent({model:"gemini-2.5-flash",contents:{parts:c},config:{systemInstruction:Y,responseMimeType:"application/json",responseSchema:A}})).text.trim(),d=JSON.parse(l);if(d!=null&&d.script)return d.script;throw new Error("Invalid script format received.")}catch(a){throw console.error("Error in generateVoiceoverScriptForSupplements:",a),new Error("Failed to generate voiceover script for supplements.")}},fe=async(r,n,o,s,e,i,t)=>{const a=g();try{const p=[{text:`Finalized Script:
${r}

Product Info: ${n}
Core Idea: ${o}
Video Format: ${s}`}];p.push({inlineData:{mimeType:"image/jpeg",data:e.split(",")[1]}}),i&&p.push({inlineData:{mimeType:"image/jpeg",data:i.split(",")[1]}}),t&&p.push({inlineData:{mimeType:"image/jpeg",data:t.split(",")[1]}});const d=(await a.models.generateContent({model:"gemini-2.5-flash",contents:{parts:p},config:{systemInstruction:J,responseMimeType:"application/json",responseSchema:S}})).text.trim(),m=JSON.parse(d);if(m!=null&&m.scenes)return m.scenes.map(w);throw new Error("Invalid storyboard format received.")}catch(c){throw console.error("Error in generatePromptsFromScriptForSupplements:",c),new Error("Failed to generate storyboard prompts for supplements.")}},ye=async(r,n)=>{const o=g();try{const e=[{text:`Product Information: ${r}`},{inlineData:{mimeType:"image/jpeg",data:n.split(",")[1]}}];return(await o.models.generateContent({model:"gemini-2.5-flash",contents:{parts:e},config:{systemInstruction:V}})).text.trim()}catch(s){throw console.error("Error generating random core idea:",s),new Error("Failed to generate a random core idea.")}},we=async(r,n,o)=>{const s=g();try{const i=[{text:`Topic: ${r}
Number of Hosts: ${n}`}];return o.forEach(a=>{i.push({inlineData:{mimeType:"image/jpeg",data:a.split(",")[1]}})}),(await s.models.generateContent({model:"gemini-2.5-flash",contents:{parts:i},config:{systemInstruction:B}})).text.trim()}catch(e){throw console.error("Error generating podcast script:",e),new Error("Failed to generate podcast script.")}},ve=async(r,n,o)=>{const s=g();try{let e=z;o==="stage"&&(e=e.replace(/podcast studio/g,"stage for a presentation"));const t=[{text:`Podcast Script:
${r}`}];n.forEach(l=>{t.push({inlineData:{mimeType:"image/jpeg",data:l.split(",")[1]}})});const c=(await s.models.generateContent({model:"gemini-2.5-pro",contents:{parts:t},config:{systemInstruction:e,responseMimeType:"application/json",responseSchema:S}})).text.trim(),p=JSON.parse(c);if(p!=null&&p.scenes)return p.scenes.map(w);throw new Error("Invalid storyboard format from podcast analysis.")}catch(e){throw console.error("Error analyzing podcast script:",e),new Error("Failed to analyze podcast script and generate scenes.")}},Se=async(r,n,o)=>{const s=g();try{const e=[{text:`Analyze these ${r.length} frames from a ${o.toFixed(1)}-second video, captured at ${n} FPS.`}];r.forEach(a=>{e.push({inlineData:{mimeType:"image/jpeg",data:a.split(",")[1]}})});const t=(await s.models.generateContent({model:"gemini-2.5-pro",contents:{parts:e},config:{systemInstruction:Z,responseMimeType:"application/json",responseSchema:X}})).text.trim();return JSON.parse(t)}catch(e){throw console.error("Error analyzing video frames:",e),new Error("Failed to analyze video frames.")}},Te=async(r,n,o,s,e,i)=>{const t=g();try{const c=[{text:`**Original Ad Analysis:**
${JSON.stringify(r,null,2)}

**New Big Idea:** ${n}
**New Product Info:** ${s||"Not provided."}
**New Target Audience:** ${e||"Not provided."}`},{inlineData:{mimeType:"image/jpeg",data:o.split(",")[1]}}];i&&c.push({inlineData:{mimeType:"image/jpeg",data:i.split(",")[1]}});const l=(await t.models.generateContent({model:"gemini-2.5-flash",contents:{parts:c},config:{systemInstruction:ee,responseMimeType:"application/json",responseSchema:A}})).text.trim(),d=JSON.parse(l);if(d!=null&&d.script)return d.script;throw new Error("Invalid script format from cloned script generation.")}catch(a){throw console.error("Error generating cloned script:",a),new Error("Failed to generate cloned script.")}},Ie=async(r,n,o,s,e,i)=>{const t=g();try{const c=[{text:`**Original Ad Analysis:**
${JSON.stringify(r,null,2)}

**New Script:**
${n}

**New Product Info:** ${s||"Not provided."}
**New Target Audience:** ${e||"Not provided."}`},{inlineData:{mimeType:"image/jpeg",data:o.split(",")[1]}}];i&&c.push({inlineData:{mimeType:"image/jpeg",data:i.split(",")[1]}});const l=(await t.models.generateContent({model:"gemini-2.5-pro",contents:{parts:c},config:{systemInstruction:te,responseMimeType:"application/json",responseSchema:S}})).text.trim(),d=JSON.parse(l);if(d!=null&&d.scenes)return d.scenes.map(w);throw new Error("Invalid storyboard format from cloned storyboard generation.")}catch(a){throw console.error("Error generating cloned storyboard:",a),new Error("Failed to generate cloned storyboard.")}},be=async(r,n)=>{const o=g(),e=[{text:`Based on the following product information and image, describe the ideal target audience for this product in a short, concise sentence.

Product Info: ${r}`},{inlineData:{mimeType:"image/jpeg",data:n.split(",")[1]}}];return(await o.models.generateContent({model:"gemini-2.5-flash",contents:{parts:e}})).text.trim()},Pe=async(r,n)=>{const o=g(),e=[{text:`Based on the following product information and image, create a single, powerful "Big Idea" or "Key Message" for an ad campaign. It should be one sentence.

Product Info: ${r}`},{inlineData:{mimeType:"image/jpeg",data:n.split(",")[1]}}];return(await o.models.generateContent({model:"gemini-2.5-flash",contents:{parts:e}})).text.trim()},Ee=async(r,n)=>{const o=g();try{const s=`**Full Script/Topic:**
${r}

**Global Visual Style:** ${n}`,i=(await o.models.generateContent({model:"gemini-2.5-pro",contents:{parts:[{text:s}]},config:{systemInstruction:re,responseMimeType:"application/json",responseSchema:S}})).text.trim(),t=JSON.parse(i);if(t!=null&&t.scenes)return t.scenes.map(w);throw new Error("Invalid storyboard format from explainer storyboard generation.")}catch(s){throw console.error("Error generating explainer storyboard:",s),new Error("Failed to generate explainer storyboard.")}},P=r=>{var e;const[n,o]=r.split(",");if(!n||!o)throw new Error("Invalid Data URL format");const s=(e=n.split(":")[1])==null?void 0:e.split(";")[0];if(!s)throw new Error("Could not determine MIME type from Data URL");return{inlineData:{mimeType:s,data:o}}},Ae=async(r,n,o,s,e,i)=>{if(!r)throw new Error("A primary reference image (reporter for two-shot, interviewee for single-shot) must be provided.");const t=g(),a=[];a.push(P(r));let c="one person (the interviewee)";e==="two-shot"&&(c=n?"two people (a reporter and an interviewee)":"one person (the reporter)",n&&a.push(P(n)));const p=`Generate a single, unique, photorealistic background scene for a street interview.

Background description: "${o}".
**CRITICAL INSTRUCTION:** The reporter MUST be holding a microphone.
The scene must have a strict ${i} aspect ratio. It should be composed to feature ${c}. Use the provided image(s) as a reference for the character(s)' appearance. The background should be the main focus, with the characters placed naturally within it. Each generation should produce a slightly different composition or angle.`,l=[...a,{text:p}],d=async()=>{const u=await t.models.generateContent({model:"gemini-2.5-flash-image",contents:{parts:l},config:{responseModalities:[x.IMAGE],imageConfig:{aspectRatio:i}}});for(const f of u.candidates[0].content.parts)if(f.inlineData)return`data:${f.inlineData.mimeType};base64,${f.inlineData.data}`;throw new Error("API did not return any image data in a chunk.")},m=Array(s).fill(null).map(()=>d()),h=await Promise.all(m);if(h.length===0)throw new Error("API did not return any images.");return h},xe=async(r,n,o)=>{const s=g();try{const i=[{text:`Topic: ${r}`},{inlineData:{mimeType:"image/jpeg",data:n.split(",")[1]}},{inlineData:{mimeType:"image/jpeg",data:o.split(",")[1]}}];return(await s.models.generateContent({model:"gemini-2.5-flash",contents:{parts:i},config:{systemInstruction:W}})).text.trim()}catch(e){throw console.error("Error generating street interview script:",e),new Error("Failed to generate street interview script.")}},je=async(r,n,o,s)=>{const e=g();try{const t=[{text:`**Finalized Script:**
${r}`},{inlineData:{mimeType:"image/jpeg",data:n.split(",")[1]}}];o&&t.push({inlineData:{mimeType:"image/jpeg",data:o.split(",")[1]}}),t.push({inlineData:{mimeType:"image/jpeg",data:s.split(",")[1]}});const c=(await e.models.generateContent({model:"gemini-2.5-pro",contents:{parts:t},config:{systemInstruction:H,responseMimeType:"application/json",responseSchema:M}})).text.trim(),p=JSON.parse(c);if(p!=null&&p.scenes&&p.reporterDescription&&p.intervieweeDescription)return{scenes:p.scenes.map(w),reporterDescription:p.reporterDescription,intervieweeDescription:p.intervieweeDescription};throw new Error("Invalid storyboard format from street interview analysis.")}catch(i){throw console.error("Error analyzing street interview script:",i),new Error("Failed to analyze script and generate scenes.")}},Ne=async(r,n)=>{const o=g();try{const e=[{text:`**Finalized Script:**
${r}`},{inlineData:{mimeType:"image/jpeg",data:n.split(",")[1]}}],t=(await o.models.generateContent({model:"gemini-2.5-pro",contents:{parts:e},config:{systemInstruction:q,responseMimeType:"application/json",responseSchema:M}})).text.trim(),a=JSON.parse(t);if(a!=null&&a.scenes&&a.reporterDescription&&a.intervieweeDescription)return{scenes:a.scenes.map(w),reporterDescription:a.reporterDescription,intervieweeDescription:a.intervieweeDescription};throw new Error("Invalid storyboard format from street interview master shot analysis.")}catch(s){throw console.error("Error analyzing street interview master shot:",s),new Error("Failed to analyze master shot and generate scenes.")}},Ce=async(r,n)=>{const o=g();try{const e=[{text:`**Topic:**
${r}`},{inlineData:{mimeType:"image/jpeg",data:n.split(",")[1]}}],t=(await o.models.generateContent({model:"gemini-2.5-pro",contents:{parts:e},config:{systemInstruction:_,responseMimeType:"application/json",responseSchema:K}})).text.trim(),a=JSON.parse(t);if(a!=null&&a.scenes&&a.reporterDescription&&a.intervieweeDescription&&a.script)return{script:a.script,scenes:a.scenes.map(w),reporterDescription:a.reporterDescription,intervieweeDescription:a.intervieweeDescription};throw new Error("Invalid format from script and storyboard master shot analysis.")}catch(s){throw console.error("Error analyzing master shot and generating script/storyboard:",s),new Error("Failed to analyze master shot and generate script/storyboard.")}},ke=async(r,n,o,s,e)=>{const i=g(),t=r.map(u=>P(u)),a=r.length,c=s==="stage"?"on a modern, well-lit stage for a presentation or talk. It could be a TED-style stage.":"in a modern, professional podcast studio with microphones.",p=`Generate a single, unique camera angle of a scene featuring ${a} ${a>1?"people":"person"} ${c}.

The scene description is: "${n}".

Use the provided reference image(s) for the appearance of the person/people. The final image must have a strict ${e} aspect ratio. The shot should be a varied angle, like a wide shot, medium shot, or over-the-shoulder angle. Each generation should produce a different angle.`,l=[...t,{text:p}],d=async()=>{const u=await i.models.generateContent({model:"gemini-2.5-flash-image",contents:{parts:l},config:{responseModalities:[x.IMAGE],imageConfig:{aspectRatio:e}}});for(const f of u.candidates[0].content.parts)if(f.inlineData)return`data:${f.inlineData.mimeType};base64,${f.inlineData.data}`;throw new Error("API did not return any image data in a chunk.")},m=Array(o).fill(null).map(()=>d()),h=await Promise.all(m);if(h.length===0)throw new Error("API did not return any images.");return h},ne="https://api2.lehuyducanh.com/api/video/generate",se="https://api2.lehuyducanh.com/api/image/generate",ae="https://api2.lehuyducanh.com/api/video/upscale",F=r=>{var e;const[n,o]=r.split(",");if(!n||!o)throw new Error("Invalid Data URL format");const s=(e=n.split(":")[1])==null?void 0:e.split(";")[0];if(!s)throw new Error("Could not determine MIME type from Data URL");return{base64:o,mimeType:s}},R=async(r,n,o=1e4,s=2e4,e=3e5)=>{var t,a;const i=Date.now();for(await new Promise(c=>setTimeout(c,s));Date.now()-i<e;){try{const c=await fetch(r,{headers:{"x-api-key":n}});if(!c.ok){console.warn(`Polling failed with status ${c.status}. Retrying...`),await new Promise(l=>setTimeout(l,o));continue}const p=await c.json();if(p.status==="COMPLETE"){if(((t=p.payload)==null?void 0:t.ready)===!0)return p.payload}else if(p.status==="FAILED")throw new Error(`Video job failed on backend: ${((a=p.error)==null?void 0:a.message)||"Unknown reason"}`)}catch(c){if(c instanceof Error&&c.message.startsWith("Video job failed"))throw c;console.error("Transient error during polling, will retry:",c)}await new Promise(c=>setTimeout(c,o))}throw new Error("Video processing timed out after "+e/1e3+" seconds.")},E=async(r,n,o=3e3,s=12e4)=>{const e=Date.now();for(;Date.now()-e<s;){try{const i=await fetch(r,{headers:{"x-api-key":n}});if(i.status===200)return await i.blob();if(i.status!==202){const t=await i.text();throw new Error(`Failed to download video (status ${i.status}): ${t}`)}}catch(i){console.error("Error during download attempt, retrying...",i)}await new Promise(i=>setTimeout(i,o))}throw new Error("Video download timed out after "+s/1e3+" seconds.")},De=async({prompt:r,aspectRatio:n,subjectUrls:o=[],styleUrl:s,sceneUrl:e,referenceUrls:i=[]})=>{var m;const t=I.getBrianApiKey();if(!t)throw new Error("Brian Image/Video API Key not found. Please configure it in the Settings module.");const c={IMAGE_ASPECT_RATIO_LANDSCAPE:"16:9",IMAGE_ASPECT_RATIO_SQUARE:"1:1",IMAGE_ASPECT_RATIO_PORTRAIT:"9:16"}[n];if(!c)throw new Error(`Unsupported aspect ratio for LeHuyDucAnh API: ${n}`);const p=(h,u)=>{const{base64:f,mimeType:v}=F(h);return{base64:f,caption:u,mimeType:v}},l=[...o,...i],d={prompt:r,cleanup:!0,aspectRatio:c};l.length>0&&(d.subjects=l.map((h,u)=>p(h,`subject reference ${u+1}`))),e&&(d.scenes=[p(e,"scene environment")]),s&&(d.styles=[p(s,"global style reference")]);try{const h=await fetch(se,{method:"POST",headers:{"Content-Type":"application/json","x-api-key":t},body:JSON.stringify(d)}),u=await h.json();if(!h.ok){const v=((m=u==null?void 0:u.error)==null?void 0:m.message)||(u==null?void 0:u.message)||JSON.stringify(u);throw new Error(`API request failed with status ${h.status}: ${v}`)}const f=u.urls||(Array.isArray(u)?u:[]);if(!Array.isArray(f)||f.length===0)throw console.error("Invalid or empty response from new image generation API:",u),new Error("Server processed the request successfully, but returned no valid images.");return f}catch(h){throw console.error("Error generating image with LeHuyDucAnh API v2:",h),h instanceof TypeError&&h.message.includes("Failed to fetch")?new Error("Failed to fetch from LeHuyDucAnh API. This is likely a CORS issue, network problem, or invalid API endpoint."):h}},Oe=async({prompt:r,startImageUrl:n,aspectRatio:o,upscale:s})=>{var i;const e=I.getBrianApiKey();if(!e)throw new Error("Brian Image/Video API Key not found. Please configure it in the Settings module.");try{const{base64:t,mimeType:a}=F(n),p=await fetch(ne,{method:"POST",headers:{"Content-Type":"application/json","x-api-key":e},body:JSON.stringify({prompt:r,generationMode:"START_ONLY",aspectRatio:o,startImage:{base64:t,mimeType:a},cleanup:!0,upscale:s})}),l=await p.json();if(!p.ok){const m=((i=l==null?void 0:l.error)==null?void 0:i.message)||(l==null?void 0:l.message)||JSON.stringify(l);throw new Error(`API Error (${p.status}): ${m}`)}const d=async m=>{var N,C,k,D,O,$;if(!m.ready||!((N=m.video)!=null&&N.url)&&!((C=m.video)!=null&&C.downloadUrl))throw new Error("Job completed but final video URL was not found.");const h=m.video.downloadUrl||m.video.url,u=await E(h,e),f=URL.createObjectURL(u);let v;const j=((D=(k=m.upscale)==null?void 0:k.video)==null?void 0:D.downloadUrl)||(($=(O=m.upscale)==null?void 0:O.video)==null?void 0:$.url);if(j)try{const b=await E(j,e);v=URL.createObjectURL(b)}catch(b){console.error("Could not fetch upscaled video, it might still be processing or failed.",b)}return{videoUrl:f,upscaledUrl:v,mediaGenerationId:m.mediaGenerationId,seed:m.seed||0}};if(l.status==="COMPLETE")return await d(l.payload);if(l.status==="PROCESSING"&&l.statusUrl){const m=await R(l.statusUrl,e,l.pollIntervalMs,6e4);return await d(m)}else throw new Error(`Unexpected initial job status: ${l.status||"Unknown"}`)}catch(t){console.error("Error generating video with LeHuyDucAnh API V2:",t);const a=t instanceof Error?t.message:"An unknown error occurred.";throw new Error(`Failed to generate video: ${a}.`)}},$e=async(r,n)=>{var s;const o=I.getBrianApiKey();if(!o)throw new Error("Brian Image/Video API Key not found. Please configure it in the Settings module.");try{const i=await fetch(ae,{method:"POST",headers:{"Content-Type":"application/json","x-api-key":o},body:JSON.stringify({mediaGenerationId:r,seed:n})}),t=await i.json();if(!i.ok){const c=((s=t==null?void 0:t.error)==null?void 0:s.message)||(t==null?void 0:t.message)||JSON.stringify(t);throw new Error(`API Error (${i.status}): ${c}`)}const a=async c=>{var d,m;if(!((d=c.video)!=null&&d.url)&&!((m=c.video)!=null&&m.downloadUrl))throw new Error("Upscale job completed, but the API did not return a video URL.");const p=c.video.downloadUrl||c.video.url,l=await E(p,o);return URL.createObjectURL(l)};if(t.status==="COMPLETE")return await a(t.payload);if(t.status==="PROCESSING"&&t.statusUrl){const c=await R(t.statusUrl,o,t.pollIntervalMs,2e4);return await a(c)}else throw new Error(`Unexpected initial upscale job status: ${t.status||"Unknown"}`)}catch(e){console.error("Error upscaling video with LeHuyDucAnh API V2:",e);const i=e instanceof Error?e.message:"An unknown error occurred.";throw new Error(`Failed to upscale video: ${i}.`)}};export{le as I,me as a,he as b,ue as c,ye as d,ge as e,fe as f,de as g,we as h,ve as i,ke as j,g as k,De as l,w as m,be as n,Pe as o,Te as p,Ie as q,Se as r,Ee as s,Ae as t,Ce as u,Ne as v,xe as w,je as x,$e as y,Oe as z};
